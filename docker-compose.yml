version: "3.3"

services:
  # This is the main postgres database for Boundary and Keycloak
  # It needs to be version >= 11
  db.localhost:
    image: postgres:15.1-alpine
    container_name: db
    ports:
      - 5432:5432
    volumes:
      - ${PWD}/configs/postgres/docker_postgres_init.sql:/docker-entrypoint-initdb.d/docker_postgres_init.sql
    environment:
      - POSTGRES_DB=root
      - POSTGRES_USER=root
      - POSTGRES_PASSWORD=changeme
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d db_boundary -U user_boundary"]
      interval: 3s
      timeout: 5s
      retries: 5
    networks:
      - "infra"

  # This initializes the Boundary database
  # Connects to db/db_boundary with user user_boundary and creates the schema
  db-init:
    container_name: boundary-db-init
    image: hashicorp/boundary:0.12
    command: ["database", "init", "-skip-auth-method-creation", "-skip-host-resources-creation", "-skip-scopes-creation", "-skip-target-creation", "-config",  "/boundary/boundary.hcl"]
    volumes:
      - ${PWD}/configs/boundary/:/boundary
    environment:
      - BOUNDARY_PG_URL=postgresql://user_boundary:changeme@db/db_boundary?sslmode=disable
    cap_add:
      - IPC_LOCK
    depends_on:
      db.localhost:
        condition: service_healthy
    networks:
    - "infra"
  # Keycloak server, used for authentication
  # It is started in dev mode so that no SSL certs are needed
  # Go to http://keycloak.localhost:8080/admin to login
  # It is extremely important to set KC_HOSTNAME or else OIDC wont work
  keycloak.localhost:
    container_name: keycloak
    image: quay.io/keycloak/keycloak:20.0.2
    environment:
      - KEYCLOAK_ADMIN=admin
      - KEYCLOAK_ADMIN_PASSWORD=admin
      - DB_VENDOR=POSTGRES
      - DB_ADDR=db
      - DB_PORT=5432
      - DB_DATABASE=db_keycloak
      - DB_USER=user_keycloak
      - DB_PASSWORD=changeme
      - KC_HOSTNAME=keycloak.localhost
      - KC_HEALTH_ENABLED=true
    ports:
      - 8080:8080
    entrypoint: ["/opt/keycloak/bin/kc.sh"]
    command: ["start-dev"]
    healthcheck:
      test: ['CMD-SHELL', '[ -f /tmp/HealthCheck.java ] || echo "public class HealthCheck { public static void main(String[] args) throws java.lang.Throwable { System.exit(java.net.HttpURLConnection.HTTP_OK == ((java.net.HttpURLConnection)new java.net.URL(args[0]).openConnection()).getResponseCode() ? 0 : 1); } }" > /tmp/HealthCheck.java && java /tmp/HealthCheck.java http://localhost:8080/health/live']
      interval: 5s
      timeout: 5s
      retries: 30
    depends_on:
      db.localhost:
        condition: service_healthy
    networks:
    - "infra"

  # The main Boundary server
  boundary.localhost:
    container_name: boundary
    image: hashicorp/boundary:0.12

    command: ["server", "-config", "/boundary/boundary.hcl"]
    volumes:
      - "${PWD}/configs/boundary:/boundary"
    ports:
      - "9200:9200"
      - "9201:9201"
      - "9202:9202"
    environment:
      - BOUNDARY_PG_URL=postgresql://user_boundary:changeme@db/db_boundary?sslmode=disable
      - HOSTNAME=boundary
    cap_add:
      - IPC_LOCK
    depends_on:
      db-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "wget", "-O-", "http://boundary.localhost:9200"]
      interval: 3s
      timeout: 5s
      retries: 5
    networks:
      - "rk-network"
      - "infra"

  # Vasult instance
  vault.localhost:
    container_name: vault
    image: vault:1.12.2
    ports:
      - "8200:8200"
    cap_add:
      - IPC_LOCK
    networks:
      - "infra"
      - "rk-network"
    entrypoint: vault server -dev -dev-listen-address="0.0.0.0:8200" -dev-root-token-id="root"

  # Our "virtual" machines
  # VM 01 is accessible via username/ password, which we store in Vault
  vm-01:
    container_name: vm-01
    image: linuxserver/openssh-server:version-9.0_p1-r2
    environment:
      - SUDO_ACCESS=true #optional
      - PASSWORD_ACCESS=true #optional
      - USER_PASSWORD=12345678 #optional
      - USER_NAME=jan #optional
    networks:
      - "rk-network"

  # VM 02 is accessible via public key (and username), which we store in Vault
  vm-02:
    container_name: vm-02
    image: linuxserver/openssh-server:version-9.0_p1-r2
    networks:
      - "rk-network"
    volumes:
      - ${PWD}/configs/openssh/vm02/key.pub:/config/key.pub
    environment:
      - PUBLIC_KEY_FILE=/config/key.pub
      - USER_NAME=vm02user

  vm-03:
    container_name: vm-03
    build:
      args:
        HTTPS_PROXY: ${https_proxy}
        NO_PROXY: ${no_proxy}
      context: ./configs/dockerfiles
      dockerfile: $PWD/configs/dockerfiles/vm-ubuntu.Dockerfile
    networks:
      rk-network:
        ipv4_address: 10.1.0.103

  vm-04:
    container_name: vm-04
    build:
      args:
        HTTPS_PROXY: ${https_proxy}
        NO_PROXY: ${no_proxy}
      context: ./configs/dockerfiles
      dockerfile: $PWD/configs/dockerfiles/vm-ubuntu.Dockerfile
    networks:
      rk-network:
        ipv4_address: 10.1.0.104

  terraform:
    container_name: terraform
    image: ghcr.io/opentofu/opentofu:latest
    volumes:
    - ${PWD}/terraform:/terraform
    - ${PWD}/configs:/configs
    working_dir: /terraform
    entrypoint: [ "sh" ]
    command:
    - -c
    - |
      tofu init
      tofu apply -auto-approve
    networks:
    - "infra"
    - "rk-network"
    env_file:
    - .proxy
    - .oauth
    depends_on:
      boundary.localhost:
        condition: service_healthy
      keycloak.localhost:
        condition: service_healthy

  tinyproxy:
    image: vimagick/tinyproxy
    ports:
      - "4080:8888"
    depends_on:
      terraform:
        condition: service_completed_successfully
    networks:
    - "infra"

  terminal:
    container_name: terminal
    build:
      context: ./configs/terminal
      dockerfile: $PWD/configs/terminal/Dockerfile
    stdin_open: true
    tty: true
    environment:
      BOUNDARY_PASS: supersecure
      BOUNDARY_LOGIN: tester01
      BOUNDARY_ADDR: http://boundary.localhost:9200
    command:
    - tail -f /dev/null
    networks:
    - "infra"
    depends_on:
      terraform:
        condition: service_completed_successfully


# We configure rk-network to use static IP addresses for the VMs
# So we can configure Vault OTP
networks:
  rk-network:
    ipam:
      driver: default
      config:
        - subnet: 10.1.0.0/24
  infra:
